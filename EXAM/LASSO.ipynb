{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Social Data Science\n",
    "Authors:\n",
    "\n",
    "Simon Guldager\n",
    "\n",
    "Astrid Waltenburg\n",
    "\n",
    "Amelia Asp\n",
    "\n",
    "Agnete Pade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from numpy import linalg as la\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('LISBON_DONE.csv')\n",
    "dat.index.name = 'Aparment'\n",
    "dat = dat.drop(columns=['Unnamed: 4'], axis=1)\n",
    "dat_filled = dat.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contains 389 rows (aparments) and 455 columns (variables).\n"
     ]
    }
   ],
   "source": [
    "print(f'The data contains {dat.shape[0]} rows (aparments) and {dat.shape[1]} columns (variables).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of columns exported to Excel: columns_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "columns = dat.columns.tolist()\n",
    "\n",
    "columns_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "excel_file_path = 'columns_output.xlsx'  # Provide the desired file path\n",
    "columns_df.to_excel(excel_file_path, index=False)\n",
    "\n",
    "print(\"List of columns exported to Excel:\", excel_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collections of variables\n",
    "\n",
    "In order to make the analysis simpler, it may be convenient to collect variables in sets that belong together naturally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pd.read_excel('columns_categories.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['Label', 'Category']\n"
     ]
    }
   ],
   "source": [
    "print(\"Column names:\", columns.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pd.read_excel('columns_categories.xlsx')\n",
    "\n",
    "# List labels #bathroom is the reference\n",
    "bedroom = []\n",
    "kitchen = []\n",
    "bath = []\n",
    "secturity = []\n",
    "entertainment = []\n",
    "parking = []\n",
    "host = []\n",
    "work = []\n",
    "family = []\n",
    "outdoor = []\n",
    "nearby = []\n",
    "temperature = []\n",
    "clothes = []\n",
    "wifi =[]\n",
    "drop = []\n",
    "\n",
    "# Extract labels where Category is 1 and add them to the corresponding lists\n",
    "bedroom_labels = columns.loc[columns['Category'] == 1, 'Label']\n",
    "bedroom.extend(bedroom_labels)\n",
    "\n",
    "kitchen_labels = columns.loc[columns['Category'] == 2, 'Label']\n",
    "kitchen.extend(kitchen_labels)\n",
    "\n",
    "bath_labels = columns.loc[columns['Category'] == 3, 'Label']\n",
    "bath.extend(bath_labels)\n",
    "\n",
    "security_labels = columns.loc[columns['Category'] == 4, 'Label']\n",
    "secturity.extend(security_labels)\n",
    "\n",
    "entertainment_labels = columns.loc[columns['Category'] == 5, 'Label']\n",
    "entertainment.extend(entertainment_labels)\n",
    "\n",
    "parking_labels = columns.loc[columns['Category'] == 6, 'Label']\n",
    "parking.extend(parking_labels)\n",
    "\n",
    "host_labels = columns.loc[columns['Category'] == 7, 'Label']\n",
    "host.extend(host_labels)\n",
    "\n",
    "work_labels = columns.loc[columns['Category'] == 8, 'Label']\n",
    "work.extend(work_labels)\n",
    "\n",
    "family_labels = columns.loc[columns['Category'] == 9, 'Label']\n",
    "family.extend(family_labels)\n",
    "\n",
    "outdoor_labels = columns.loc[columns['Category'] == 10, 'Label']\n",
    "outdoor.extend(outdoor_labels)\n",
    "\n",
    "nearby_labels = columns.loc[columns['Category'] == 11, 'Label']\n",
    "nearby.extend(nearby_labels)\n",
    "\n",
    "temperature_labels = columns.loc[columns['Category'] == 12, 'Label']\n",
    "temperature.extend(temperature_labels)\n",
    "\n",
    "clothes_labels = columns.loc[columns['Category'] == 13, 'Label']\n",
    "clothes.extend(clothes_labels)\n",
    "\n",
    "wifi_labels = columns.loc[columns['Category'] == 14, 'Label']\n",
    "wifi.extend(wifi_labels)\n",
    "\n",
    "drop_labels = columns.loc[columns['Category'] == 15, 'Label']\n",
    "drop.extend(drop_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15      hurtig wi-fi – 205 m\n",
       "42         trådløst internet\n",
       "101    wi-fi – 45 mbps\\nbekr\n",
       "143     ethernet-forbindelse\n",
       "145     hurtig wi-fi – 347 m\n",
       "152    wi-fi – 19 mbps\\nbekr\n",
       "Name: Label, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wifi_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store all the lists\n",
    "vv_all = {\n",
    "    'bedroom': bedroom,\n",
    "    'kitchen': kitchen,\n",
    "    'bath': bath,\n",
    "    'security': secturity,\n",
    "    'entertainment': entertainment,\n",
    "    'parking': parking,\n",
    "    'host': host,\n",
    "    'work': work,\n",
    "    'family': family,\n",
    "    'outdoor': outdoor,\n",
    "    'nearby': nearby,\n",
    "    'temperature': temperature,\n",
    "    'clothes': clothes,\n",
    "    'wifi': wifi\n",
    "}\n",
    "list_of_lists = vv_all.values()\n",
    "vv_all['all'] = [v for sublist in list_of_lists for v in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenient to keep a column of ones in the dataset\n",
    "dat['constant'] = np.ones((dat.shape[0],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = []\n",
    "# Iterate through each category in vv_all and concatenate its list to zs\n",
    "for category_list in vv_all.values():\n",
    "    zs += category_list\n",
    "ds = ['TS_dummy'] #Taylor Swift dummy\n",
    "xs = ds + zs\n",
    "\n",
    "# avoiding missings, e.g. in omtaler og host\n",
    "all_vars = ['price'] + xs\n",
    "I = dat[all_vars].notnull().all(1)\n",
    "\n",
    "# extract data\n",
    "X = dat.loc[I, xs].values\n",
    "Z = dat.loc[I, zs].values\n",
    "D = dat.loc[I, ds].values\n",
    "y = dat.loc[I,'price'].values.reshape((-1,1)) * 100\n",
    "\n",
    "# check the rank condition\n",
    "K = X.shape[1]\n",
    "assert np.linalg.matrix_rank(X) == X.shape[1], f'X does not have full rank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS: No controls\n",
    "cD = np.concatenate((np.ones_like(D),D),axis = 1)\n",
    "\n",
    "betahat = np.linalg.inv(cD.T @ cD) @ cD.T @ y\n",
    "SSR_none = (y - cD@betahat).T@(y - cD@betahat)\n",
    "\n",
    "sigma2 = (np.array(SSR_none/(cD.shape[0] - cD.shape[1])))\n",
    "cov = sigma2*la.inv(cD.T@cD)\n",
    "se_none = np.sqrt(cov.diagonal()).reshape(-1, 1)\n",
    "\n",
    "OLS_none = betahat[1]\n",
    "\n",
    "OLS_CI = OLS_none + norm.ppf(0.975)*np.array([-se_none[1].item(),se_none[1].item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions = PolynomialFeatures(interaction_only=True, include_bias = False)\n",
    "Z_int = interactions.fit_transform(Z)   # Creating control variables with interaction terms\n",
    "int_names = interactions.get_feature_names_out(zs)\n",
    "\n",
    "i_idx = []      # defining list to seperate index of variables and interaction terms with variance. \n",
    "                # the looping as below is bad code, as it could be written as a one-liner\n",
    "\n",
    "for i in range(Z_int.shape[1]):\n",
    "    if np.std(Z_int[:,i]) != 0:\n",
    "        i_idx.append(i)\n",
    "\n",
    "Z_int = Z_int[:,i_idx]      # dropping interaction terms with out variance\n",
    "idx_ = int_names[i_idx]     # dropping variable names of interaction terms without variance\n",
    "X_int = np.concatenate((D,Z_int),axis = 1)          # Creating all variables with interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y is not reshaped, as otherwise all LASSO predicts should be reshaped to ensure the correct dimension of the residuals (otherwise they will be (no aparmtnets,no apartments))\n",
    "# not reshaping y has no influence on the below OLS calculations. D is flattened for the same reason\n",
    "y = dat.loc[I, 'price'] * 100.0        \n",
    "X = dat.loc[I, xs].values\n",
    "D = D.flatten()\n",
    "len_some = len(X)\n",
    "contr_some = len(xs) - 1\n",
    "\n",
    "betahat = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "SSR_some = (y - X@betahat).T@(y - X@betahat)\n",
    "\n",
    "sigma2 = (np.array(SSR_some/(X.shape[0] - X.shape[1])))\n",
    "cov = sigma2*la.inv(X.T@X)\n",
    "se_some = np.sqrt(cov.diagonal()).reshape(-1, 1)\n",
    "\n",
    "OLS_some = betahat[1]\n",
    "OLS_CI = OLS_some + norm.ppf(0.975)*np.array([-se_some[1].item(),se_some[1].item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X):\n",
    "    X_mean = np.mean(X,axis=0)\n",
    "    X_std = np.std(X,axis=0)\n",
    "    X_stan = (X-X_mean)/X_std\n",
    "    return X_stan\n",
    "\n",
    "X_stan = standardize(X)\n",
    "Z_stan = standardize(Z)\n",
    "Z_int_stan = standardize(Z_int)\n",
    "X_int_stan = standardize(X_int)\n",
    "D_stan = standardize(D)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining penalty term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BRT(X_tilde,y):\n",
    "    (N,p) = X_tilde.shape\n",
    "    sigma = np.std(y)\n",
    "    c = 1.1\n",
    "    alpha = 0.05\n",
    "\n",
    "    penalty_BRT = (sigma * c)/np.sqrt(N)*norm.ppf(1-alpha/(2*p))\n",
    "\n",
    "    return penalty_BRT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Double Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating penalty terms\n",
    "penalty_BRTdz = BRT(Z_stan,D)\n",
    "penalty_BRTdz_1 = BRT(Z_int_stan,D)\n",
    "\n",
    "# Lasso on Taylor Swift dummy\n",
    "fit_BRTdz = Lasso(alpha=penalty_BRTdz).fit(Z_stan,D) \n",
    "fit_BRTdz_1 = Lasso(alpha=penalty_BRTdz_1).fit(Z_int_stan,D) \n",
    "\n",
    "# Save residuals\n",
    "resdz = D - fit_BRTdz.predict(Z_stan)\n",
    "resdz_1 = D - fit_BRTdz_1.predict(Z_int_stan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating penalty terms\n",
    "penalty_BRTyx = BRT(X_stan,y)\n",
    "penalty_BRTyx_1 = BRT(X_int_stan,y)\n",
    "\n",
    "# Lasso on aparment price\n",
    "fit_BRTyx = Lasso(alpha=penalty_BRTyx).fit(X_stan,y) \n",
    "fit_BRTyx_1 = Lasso(alpha=penalty_BRTyx_1).fit(X_int_stan,y) \n",
    "\n",
    "# Lasso coefficients\n",
    "coefs = fit_BRTyx.coef_\n",
    "coefs_1 = fit_BRTyx_1.coef_\n",
    "\n",
    "# save residuals\n",
    "resyxz = y-fit_BRTyx.predict(X_stan) + D_stan*coefs[0]\n",
    "resyxz_1 = y-fit_BRTyx_1.predict(X_int_stan) + D_stan*coefs_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PDL_ols(resdz,resyxz,d):\n",
    "    denom = np.sum(resdz*d)\n",
    "    num = np.sum(resdz*resyxz)\n",
    "    return num/denom\n",
    "\n",
    "def PDL_CI(resdz,resyzz):\n",
    "    # Variance\n",
    "\n",
    "    N = resyzz.shape[0]\n",
    "    num = np.sum(resdz**2*resyzz**2)/N\n",
    "    denom = (np.sum(resdz**2)/N)**2\n",
    "    sigma2_PDL = num/denom\n",
    "\n",
    "    # Confidence interval\n",
    "    q=norm.ppf(1-0.025)\n",
    "    se_PDL = np.sqrt(sigma2_PDL/N)      # calculating standard error as the squareroot of the mean variance\n",
    "    CI_PDL=(((PDL-q*se_PDL).round(2),(PDL+q*se_PDL).round(2)))\n",
    "\n",
    "    return se_PDL, CI_PDL\n",
    "\n",
    "# Save residuals\n",
    "resyzz = y - fit_BRTyx.predict(X_stan)\n",
    "resyzz_1 = y - fit_BRTyx_1.predict(X_int_stan)\n",
    "\n",
    "# Estimating Post Double Lasso\n",
    "PDL = PDL_ols(resdz,resyxz,D)\n",
    "PDL_1 = PDL_ols(resdz_1,resyxz_1,D)\n",
    "\n",
    "# estimating standard errors and confidence interval for Post Double Lasso\n",
    "se_PDL, CI_PDL = PDL_CI(resdz, resyzz)\n",
    "se_PDL_1, CI_PDL_1 = PDL_CI(resdz_1, resyzz_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "{} &      (1) &      (2) &      (3) &      (4) &      (5) &      (6) \\\\\n",
      "\\midrule\n",
      "                      &      OLS &      OLS &      PDL &      PDL &      PDL &      PDL \\\\\n",
      "Initial $\\log{(gdp)}$ &  -0.1214 &  -0.1548 &  -0.2359 &  -0.1756 &  -0.1268 &  -0.1214 \\\\\n",
      "se                    &   0.1237 &   0.7959 &   0.2226 &   0.1932 &   0.1469 &   0.1433 \\\\\n",
      "No controls           &        0 &       34 &       34 &      588 &       34 &      588 \\\\\n",
      "No obs                &       70 &       70 &       70 &       70 &       70 &       70 \\\\\n",
      "$\\lambda^{dz}$        &          &          &   0.5724 &   0.7073 &   0.9139 &   1.2401 \\\\\n",
      "$\\lambda^{yx}$        &          &          &   0.5896 &   0.7267 &   1.2538 &   2.7735 \\\\\n",
      "t-statistic           &  -0.9814 &  -0.1945 &  -1.0597 &  -0.9089 &  -0.8632 &  -0.8472 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fj/trr23jhx25j8_78nf00613400000gn/T/ipykernel_6304/1949971474.py:20: FutureWarning:\n",
      "\n",
      "In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estimates\n",
    "\n",
    "estimates = np.array([OLS_none[0], OLS_some, PDL, PDL_1]).round(4)\n",
    "label_over_column = ['(1)','(2)','(3)','(4)']\n",
    "label_column = np.array(['OLS', 'OLS', 'PDL', 'PDL'])\n",
    "label_row = ['' ,'Initial $\\log{(gdp)}$', 'se', 'No controls','No obs','$\\lambda^{dz}$','$\\lambda^{yx}$','t-statistic']\n",
    "se = np.array([se_none[1].item(),se_some[1].item(),se_PDL, se_PDL_1]).round(4)\n",
    "no_controls = np.array([0, contr_some, len(zs), Z_int_stan.shape[1], len(zs), Z_int_stan.shape[1]])\n",
    "no_obs = np.array([len(y), len(y), len(y), len(y), len(y), len(y)])\n",
    "\n",
    "pens_dz = np.array(['','', penalty_BRTdz.round(4), penalty_BRTdz_1.round(4)])\n",
    "pens_yx = np.array(['','', penalty_BRTyx.round(4), penalty_BRTyx_1.round(4)])\n",
    "\n",
    "t_statistic = (estimates/se).round(4)    \n",
    "\n",
    "data = np.row_stack((label_column ,estimates, se, no_controls,no_obs, pens_dz, pens_yx,t_statistic))\n",
    "\n",
    "df = pd.DataFrame(data = data, index = label_row, columns = label_over_column)\n",
    "\n",
    "print(df.to_latex(escape = False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table with estimates of control variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &      dz &      yx \\\\\n",
      "\\midrule\n",
      "abslat      &  0.2440 &  0.0000 \\\\\n",
      "asia        & -0.0000 &  0.0871 \\\\\n",
      "currentinst & -0.0000 & -0.0008 \\\\\n",
      "lh_bl       &  0.0285 &  0.0000 \\\\\n",
      "lp_bl       &  0.0928 &  0.0000 \\\\\n",
      "ls_bl       &  0.1319 &  0.0000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fj/trr23jhx25j8_78nf00613400000gn/T/ipykernel_6304/3417109994.py:3: FutureWarning:\n",
      "\n",
      "In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LASSO estimates - BRT with out interactions\n",
    "df_tab = pd.DataFrame(data = np.row_stack((fit_BRTdz.coef_,fit_BRTyx.coef_[1:])).T, index = zs,columns = ['dz','yx']) # collecting all estimates for both stages, exluding log(gdp)\n",
    "print(df_tab.loc[~(df_tab==0).all(axis=1)].round(4).to_latex(escape=False)) # removing all estimates equal to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &      dz &      yx \\\\\n",
      "\\midrule\n",
      "abslat marketref &  0.1245 &  0.0000 \\\\\n",
      "abslat lp_bl     &  0.0966 &  0.0000 \\\\\n",
      "abslat ls_bl     &  0.0144 &  0.0000 \\\\\n",
      "cenlong asia     & -0.0000 &  0.0951 \\\\\n",
      "lh_bl lp_bl      &  0.0629 &  0.0000 \\\\\n",
      "lp_bl ls_bl      &  0.0818 &  0.0000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fj/trr23jhx25j8_78nf00613400000gn/T/ipykernel_6304/2173753093.py:3: FutureWarning:\n",
      "\n",
      "In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LASSO estimates - BRT with interaction terms\n",
    "df_tab_int = pd.DataFrame(data = np.row_stack((fit_BRTdz_1.coef_,fit_BRTyx_1.coef_[1:])).T, index = idx_,columns = ['dz','yx']) # using idx_, as this variable is control variable names, adjusted for those delted due to no variance\n",
    "print(df_tab_int.loc[~(df_tab_int==0).all(axis=1)].round(4).to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &      dz &   yx \\\\\n",
      "\\midrule\n",
      "abslat &  0.0249 &  0.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fj/trr23jhx25j8_78nf00613400000gn/T/ipykernel_6304/2027556558.py:3: FutureWarning:\n",
      "\n",
      "In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LASSO estimates - BCCH without interaction terms\n",
    "df_tab_int = pd.DataFrame(data = np.row_stack((fit_BCCHdz.coef_,fit_BCCHyx.coef_[1:])).T, index = zs,columns = ['dz','yx']) # using idx_, as this variable is control variable names, adjusted for those delted due to no variance\n",
    "print(df_tab_int.loc[~(df_tab_int==0).all(axis=1)].round(4).to_latex(escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "Empty DataFrame\n",
      "Columns: Index(['dz', 'yx'], dtype='object')\n",
      "Index: Index([], dtype='object') \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fj/trr23jhx25j8_78nf00613400000gn/T/ipykernel_6304/1174392149.py:4: FutureWarning:\n",
      "\n",
      "In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LASSO estimates - BCCH with interaction terms\n",
    "df_tab_int = pd.DataFrame(data = np.row_stack((fit_BCCHdz_1.coef_,fit_BCCHyx_1.coef_[1:])).T, index = idx_,columns = ['dz','yx'])\n",
    "# no non-zero control variables\n",
    "print(df_tab_int.loc[~(df_tab_int==0).all(axis=1)].round(4).to_latex(escape=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1091f1b9584b16126d959e1e6baecccd273f82381826b825c44bca03b6114737"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
